{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TF-IDF Predictor with Scikit-learn: Proof of Concept\n",
    "\n",
    "**Term Frequency-Inverse Document Frequency** (TF-IDF) is an information retrieval (IR) statistic used to determine how important a word is to a document. Simply put, we determine the TF-IDF of a word in a document by counting the occurrences of that word in the document, then dividing it by the number of documents in which it appears. Then, this process is repeated for each word in the document, resulting in a vector indicating the relevance of each word to that document. It's a simple, but effective IR method that was introduced in the 1980s, yet has stood the test of time.\n",
    "\n",
    "The bread and butter of IR is the process of turning arbitrary-length documents into fixed-length vectors (other such methods include word embeddings, encode-decode model, etc.). Once we have vectors that abstractly represent the semantics of documents, we can compare such vectors using metrics like cosine similarity, i.e. the dot product between two vectors. This principle then forms the basis of our project - *using TF-IDF, we map a small query and large documents into a high-dimensional vector space, then determine which documents are most relevant to the query*. In essence, it is a search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Update and import dependencies\n",
    "!pip install -Uqr requirements.txt\n",
    "\n",
    "# Basic packages\n",
    "import importlib\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from progress.bar import Bar\n",
    "import io\n",
    "\n",
    "# Data science/NLP packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# AWS packages\n",
    "import boto3\n",
    "\n",
    "# Local modules\n",
    "import tfidf_predictor\n",
    "import train_tfidf\n",
    "for m in [tfidf_predictor, train_tfidf]:\n",
    "    importlib.reload(m)\n",
    "\n",
    "from tfidf_predictor import VectorSimilarity, TfidfPredictor\n",
    "from train_tfidf import combine_dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extending SKLearn: VectorSimilarity\n",
    "\n",
    "In order to perform pairwise comparisons across vectors and find the most similar pairs, we implemented the `VectorSimilarity` class, extending SKLearn's Estimator interface."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visual representation of vector locations\n",
    "\n",
    "       /\\\n",
    "        b  ?\n",
    "        |\n",
    "        |\n",
    "< c --------- a >\n",
    "        |\n",
    "        |\n",
    "        d\n",
    "       \\/\n",
    "\"\"\"\n",
    "X = np.array(\n",
    "    [[1, 0],\n",
    "     [0, 1],\n",
    "     [-1, 0],\n",
    "     [0, -1]]\n",
    ")\n",
    "y = np.array(['a', 'b', 'c', 'd'])\n",
    "\n",
    "sim_estimator = VectorSimilarity(n_best=10)\n",
    "sim_estimator = sim_estimator.fit(X, y)\n",
    "\n",
    "vec_input = np.array([0.5, 1]).reshape(1, -1) # Shape needs to be (1, n)\n",
    "pred, score = sim_estimator.predict(vec_input)\n",
    "print('Most similar vectors:\\n', pred)\n",
    "print('Confidence scores:\\n', score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.06862807273864746 seconds\n",
      "[['a' 'c' 'b' 'd']\n",
      " ['b' 'c' 'a' 'd']\n",
      " ['c' 'b' 'a' 'd']\n",
      " ['d' 'c' 'b' 'a']]\n",
      "[[1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olileung/.pyenv/versions/3.9.5/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "basic_corpus = [\n",
    "    'Bees like to make honey',\n",
    "    'Bears like to eat honey',\n",
    "    \"Bees don't like bears\",\n",
    "    'Humans are walking around the park'\n",
    "]\n",
    "basic_labels = ['a', 'b', 'c', 'd']\n",
    "\n",
    "tfidf_model = TfidfPredictor(lemmatize='custom')\n",
    "tfidf_model.fit(basic_corpus, basic_labels, verbose=True)\n",
    "pred, score = tfidf_model.predict(basic_corpus)\n",
    "print(pred)\n",
    "print(score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# File helper functions\n",
    "def list_data_objs():\n",
    "    secret_name = \"SageMakerS3Access\"\n",
    "    region_name = \"us-west-2\"\n",
    "    bucket_name = 'amplifyobserverinsights-aoinsightslandingbucket29-5vcr471d4nm5'\n",
    "    bucket_subfolder = 'data/issues/'\n",
    "\n",
    "#     secrets = boto3.client(\n",
    "#         service_name='secretsmanager',\n",
    "#         region_name=region_name\n",
    "#     )\n",
    "\n",
    "#     secrets_response = secrets.get_secret_value(SecretId=secret_name)\n",
    "#     secrets_dict = json.loads(secrets_response['SecretString'])\n",
    "#     (access_key, secret_key), = secrets_dict.items()\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    data_objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=bucket_subfolder)['Contents']\n",
    "    data_obj_names = [key['Key'] for key in data_objects]\n",
    "#     data_obj_names = [f\"s3://{bucket_name}/{key['Key']}\" for key in data_objects]\n",
    "\n",
    "    return data_obj_names\n",
    "\n",
    "\n",
    "def download_data(filename, data_obj_names):\n",
    "    dfs = []\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "    )\n",
    "\n",
    "    with Bar(\n",
    "        message='Downloading parquets',\n",
    "        check_tty=False,\n",
    "        hide_cursor=False,\n",
    "        max=len(data_obj_names)\n",
    "    ) as bar:\n",
    "\n",
    "        for obj_name in data_obj_names:\n",
    "#             df = wr.s3.read_csv(obj_name)\n",
    "            obj = s3.get_object(Bucket='amplifyobserverinsights-aoinsightslandingbucket29-5vcr471d4nm5', Key=obj_name)\n",
    "            df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "            dfs.append(df)\n",
    "            bar.next()\n",
    "\n",
    "        bar.finish()\n",
    "\n",
    "    df = combine_dfs(dfs)\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_data(filename, force_redownload=False):\n",
    "    start = time()\n",
    "    data = Path(filename)\n",
    "\n",
    "    if data.is_file() and not force_redownload:\n",
    "        print('Deserializing data from', filename, '...')\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "    else:\n",
    "        data_obj_names = list_data_objs()\n",
    "        df = download_data(filename, data_obj_names[1:]) # TODO: this is because list data objs is returning an empty thing\n",
    "\n",
    "    print('Took', time() - start, 'seconds')\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/kk/qnprwmz50wj1r0y6m0jr7jgc0000gs/T/ipykernel_35853/3557077644.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'training_data.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_redownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/kk/qnprwmz50wj1r0y6m0jr7jgc0000gs/T/ipykernel_35853/687310177.py\u001B[0m in \u001B[0;36mget_data\u001B[0;34m(filename, force_redownload)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0mdata_obj_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist_data_objs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m         \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdownload_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_obj_names\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# TODO: this is because list data objs is returning an empty thing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/kk/qnprwmz50wj1r0y6m0jr7jgc0000gs/T/ipykernel_35853/687310177.py\u001B[0m in \u001B[0;36mlist_data_objs\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0ms3\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mboto3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m's3'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m     \u001B[0mdata_objects\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ms3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist_objects_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBucket\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbucket_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPrefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbucket_subfolder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Contents'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m     \u001B[0mdata_obj_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Key'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata_objects\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m#     data_obj_names = [f\"s3://{bucket_name}/{key['Key']}\" for key in data_objects]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/botocore/client.py\u001B[0m in \u001B[0;36m_api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    384\u001B[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001B[1;32m    385\u001B[0m             \u001B[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 386\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_api_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moperation_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m         \u001B[0m_api_call\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpy_operation_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/botocore/client.py\u001B[0m in \u001B[0;36m_make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m    703\u001B[0m             \u001B[0merror_code\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsed_response\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Error\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Code\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m             \u001B[0merror_class\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_code\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 705\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0merror_class\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparsed_response\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperation_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    706\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    707\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mparsed_response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mClientError\u001B[0m: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied"
     ]
    }
   ],
   "source": [
    "df = get_data('training_data.csv', force_redownload=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train model\n",
    "corpus_col='title_body'\n",
    "url_col = 'url'\n",
    "title_col='title'\n",
    "train_df = df\n",
    "\n",
    "corpus = train_df[corpus_col]\n",
    "labels = list(zip(train_df[url_col], train_df[title_col]))\n",
    "\n",
    "pipe = get_fitted_model(corpus, labels, lemmatize='custom')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}