{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TF-IDF Predictor with Scikit-learn: Proof of Concept\n",
    "\n",
    "**Term Frequency-Inverse Document Frequency** (TF-IDF) is an information retrieval (IR) statistic used to determine how important a word is to a document. Simply put, we determine the TF-IDF of a word in a document by counting the occurrences of that word in the document, then dividing it by the number of documents in which it appears. Then, this process is repeated for each word in the document, resulting in a vector indicating the relevance of each word to that document. It's a simple, but effective IR method that was introduced in the 1980s, yet has stood the test of time.\n",
    "\n",
    "The bread and butter of IR is the process of turning arbitrary-length documents into fixed-length vectors (other such methods include word embeddings, encode-decode model, etc.). Once we have vectors that abstractly represent the semantics of documents, we can compare such vectors using metrics like cosine similarity, i.e. the dot product between two vectors. This principle then forms the basis of our project - *using TF-IDF, we map a small query and large documents into a high-dimensional vector space, then determine which documents are most relevant to the query*. In essence, it is a search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update and import dependencies\n",
    "!pip install -Uqr requirements.txt\n",
    "\n",
    "# Basic packages\n",
    "import importlib\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from progress.bar import Bar\n",
    "import io\n",
    "\n",
    "# Data science/NLP packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# AWS packages\n",
    "import boto3\n",
    "\n",
    "# Local modules\n",
    "import tfidf_predictor, utils_tfidf, train_tfidf\n",
    "for m in [tfidf_predictor, utils_tfidf, train_tfidf]:\n",
    "    importlib.reload(m)\n",
    "\n",
    "from tfidf_predictor import VectorSimilarity, TfidfPredictor\n",
    "from train_tfidf import combine_dfs\n",
    "from utils_tfidf import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending SKLearn: VectorSimilarity\n",
    "\n",
    "In order to perform pairwise comparisons across vectors and find the most similar pairs, we implemented the `VectorSimilarity` class, extending SKLearn's Estimator interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar vectors:\n",
      " [['b' 'a' 'c' 'd']]\n",
      "Confidence scores:\n",
      " [[ 1.   0.5 -0.5 -1. ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visual representation of vector locations\n",
    "\n",
    "       /\\\n",
    "        b  ?\n",
    "        |\n",
    "        |\n",
    "< c --------- a >\n",
    "        |\n",
    "        |\n",
    "        d\n",
    "       \\/\n",
    "\"\"\"\n",
    "X = np.array(\n",
    "    [[1, 0],\n",
    "     [0, 1],\n",
    "     [-1, 0],\n",
    "     [0, -1]]\n",
    ")\n",
    "y = np.array(['a', 'b', 'c', 'd'])\n",
    "\n",
    "sim_estimator = VectorSimilarity(n_best=10)\n",
    "sim_estimator = sim_estimator.fit(X, y)\n",
    "\n",
    "vec_input = np.array([0.5, 1]).reshape(1, -1) # Shape needs to be (1, n)\n",
    "pred, score = sim_estimator.predict(vec_input)\n",
    "print('Most similar vectors:\\n', pred)\n",
    "print('Confidence scores:\\n', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 1.770897626876831 seconds\n",
      "[['a' 'c' 'b' 'd']\n",
      " ['b' 'c' 'a' 'd']\n",
      " ['c' 'b' 'a' 'd']\n",
      " ['d' 'c' 'b' 'a']]\n",
      "[[1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.27710268 0.27710268 0.        ]\n",
      " [1.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "basic_corpus = [\n",
    "    'Bees like to make honey',\n",
    "    'Bears like to eat honey',\n",
    "    \"Bees don't like bears\",\n",
    "    'Humans are walking around the park'\n",
    "]\n",
    "basic_labels = ['a', 'b', 'c', 'd']\n",
    "\n",
    "tfidf_model = TfidfPredictor(lemmatize='custom')\n",
    "tfidf_model.fit(basic_corpus, basic_labels, verbose=True)\n",
    "pred, score = tfidf_model.predict(basic_corpus)\n",
    "print(pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deserializing data from training_data.csv took 0.21923613548278809 seconds\n",
      "(17253, 7)\n",
      "Index(['Unnamed: 0', 'repo', 'title_body', 'title', 'id', 'url', 'number'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = get_data('training_data.csv', force_redownload=False, verbose=True)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 80.04574918746948 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "corpus_col='title_body'\n",
    "url_col = 'url'\n",
    "title_col='title'\n",
    "train_df = df\n",
    "\n",
    "corpus = train_df[corpus_col]\n",
    "labels = list(zip(train_df[url_col], train_df[title_col]))\n",
    "\n",
    "tfidf_model = TfidfPredictor(lemmatize='custom')\n",
    "tfidf_model.fit(corpus, labels, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab words: 23685\n",
      "Available repos: ['amplify-js', 'amplify-adminui', 'aws-appsync-realtime-client-ios', 'amplify-ui', 'amplify-ci-support', 'amplify-console', 'amplify-observer', 'docs', 'aws-sdk-android', 'amplify-js-samples', 'amplify-cli', 'amplify-ios', 'aws-amplify.github.io', 'amplify-flutter', 'community', 'amplify-android', 'aws-sdk-ios', 'amplify-codegen']\n"
     ]
    }
   ],
   "source": [
    "# Model stats\n",
    "vocab = tfidf_model._vectorizer.get_feature_names()\n",
    "print('Number of vocab words:', len(vocab))\n",
    "repo_list = list(set(df['repo']))\n",
    "print('Available repos:', repo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 2.404874086380005 seconds\n",
      "[[['https://github.com/aws-amplify/amplify-js/issues/8472'\n",
      "   'AmplifySignIn component does not work with password managers or native browser autofill']\n",
      "  ['https://github.com/aws-amplify/amplify-adminui/issues/233'\n",
      "   'Password managers, remember password, and suggest password not working in login form']\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/5782'\n",
      "   \"(React) UI Components don't support password managers\"]\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/8289'\n",
      "   \"Password managers don't seem to auto-fill login credentials in AmplifyAuthenticator -> AmplifySignIn\"]\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/4748'\n",
      "   \"[VueJS] Firefox autofill don't work\"]\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/3799'\n",
      "   'Password reset issue - chrome autofill']\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/14'\n",
      "   'Forgot password / change password?']\n",
      "  ['https://github.com/aws-amplify/aws-sdk-ios/issues/3076'\n",
      "   'Add Support to Swift Package Manager']\n",
      "  ['https://github.com/aws-amplify/aws-sdk-ios/issues/313'\n",
      "   'Support Swift Package Manager']\n",
      "  ['https://github.com/aws-amplify/amplify-js/issues/6111'\n",
      "   'Svelte UI Components']]]\n"
     ]
    }
   ],
   "source": [
    "pw_mgr_query = ['AmplifySignIn component does not work with password managers or native browser autofill']\n",
    "pred, score = tfidf_model.predict(pw_mgr_query, verbose=True)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
