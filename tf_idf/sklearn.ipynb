{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from time import time\n",
    "from progress.bar import Bar\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import awswrangler as wr\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import vector_similarity\n",
    "importlib.reload(vector_similarity)\n",
    "from vector_similarity import VectorSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', 'b', 'c']], dtype='<U1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checks on VectorSimilarity\n",
    "\n",
    "# check_estimator(VectorSimilarity())\n",
    "X = np.array(\n",
    "    [[0, 1],\n",
    "     [1, 0],\n",
    "     [-1, 0]])\n",
    "y = np.array(['a', 'b', 'c'])\n",
    "\n",
    "estimator = VectorSimilarity()\n",
    "estimator = estimator.fit(X, y)\n",
    "estimator.predict(np.array([1, 2]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a' 'b' 'c' 'd']\n",
      " ['b' 'a' 'c' 'd']\n",
      " ['c' 'b' 'a' 'd']\n",
      " ['d' 'c' 'b' 'a']]\n",
      "[[1.         0.50443175 0.3494023  0.        ]\n",
      " [1.         0.50443175 0.3494023  0.        ]\n",
      " [1.         0.3494023  0.3494023  0.        ]\n",
      " [1.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Basic pipeline setup\n",
    "\n",
    "basic_corpus = [\n",
    "    'Bees like to make honey',\n",
    "    'Bears like to eat honey',\n",
    "    'Bees don\\'t like bears',\n",
    "    'Humans are walking around the park'\n",
    "]\n",
    "basic_labels = ['a', 'b', 'c', 'd']\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(), VectorSimilarity())\n",
    "pipe.fit(basic_corpus, basic_labels)\n",
    "print(pipe.predict(basic_corpus))\n",
    "print(pipe.score(basic_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "chunksize = 1000\n",
    "output_content_type = \"parquet\"\n",
    "flow_export_id = f\"30-23-06-49-58efbaf1\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "s3_output_prefix = f\"export-{flow_export_name}/output\"\n",
    "s3_output_path = f\"s3://{bucket}/{s3_output_prefix}\"\n",
    "\n",
    "if output_content_type.upper() == \"CSV\":\n",
    "    dfs = wr.s3.read_csv(s3_output_path, chunksize=chunksize)\n",
    "elif output_content_type.upper() == \"PARQUET\":\n",
    "    dfs = wr.s3.read_parquet(s3_output_path, chunked=chunksize)\n",
    "else:\n",
    "    print(f\"Unexpected output content type {output_content_type}\") \n",
    "\n",
    "df = next(dfs)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['https://github.com/aws-amplify/amplify-adminui/issues/12'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/21'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/67'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/82'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/41'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/28'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/85'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/45'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/35'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/33']]\n",
      "[[1.         0.6949403  0.23125501 0.13250384 0.12011294 0.12004747\n",
      "  0.11126224 0.08492276 0.08372554 0.07978957]]\n",
      "['https://github.com/aws-amplify/amplify-adminui/issues/12']\n"
     ]
    }
   ],
   "source": [
    "X = df['bodyText']\n",
    "y = df['url']\n",
    "pipe.fit(X, y)\n",
    "print(pipe.predict(X[13:14]))\n",
    "print(pipe.score(X[13:14]))\n",
    "print(list(y[13:14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading parquets |####                            | 63/426Downloading parquets |                                | 12/426"
     ]
    }
   ],
   "source": [
    "# Download raw parquets\n",
    "secret_name = \"SageMakerS3Access\"\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "client = boto3.client(\n",
    "    service_name='secretsmanager',\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "secrets_response = client.get_secret_value(\n",
    "    SecretId=secret_name\n",
    ")\n",
    "secrets_dict = json.loads(secrets_response['SecretString'])\n",
    "(access_key, secret_key), = secrets_dict.items()\n",
    "\n",
    "# session._session.set_credentials(access_key, secret_key)\n",
    "\n",
    "bucket_name = 'githubmachinelearningstack-rawdatabucket79e6ae92-dvgbsz21ce9v'\n",
    "bucket_subfolder = 'data/'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "data_objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=bucket_subfolder)['Contents']\n",
    "data_obj_names = [key['Key'] for key in data_objects]\n",
    "dfs = []\n",
    "\n",
    "start_time = time()\n",
    "with Bar(message='Downloading parquets', check_tty=False, hide_cursor=False, max=len(data_obj_names)) as bar:\n",
    "    for obj_name in data_obj_names:\n",
    "        full_obj_name = f\"s3://{bucket_name}/{obj_name}\"\n",
    "        df = wr.s3.read_parquet(full_obj_name)\n",
    "        dfs.append(df)\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "print('Took ', time() - start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949593544006348 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "df = pd.concat(dfs)\n",
    "print(f\"{time() - start_time} seconds\")\n",
    "\n",
    "df = df[(not isinstance(df.bodyText, str)) and (df.bodyText != '')]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not isinstance(row['bodyText'], str) or row['bodyText'] == '':\n",
    "        print(row['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.218099117279053\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "pipe = make_pipeline(TfidfVectorizer(), VectorSimilarity())\n",
    "small_df = df\n",
    "corpus = small_df['bodyText']\n",
    "labels = small_df['url']\n",
    "pipe.fit(corpus, labels)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['https://github.com/aws-amplify/amplify-adminui/issues/12'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/21'\n",
      "  'https://github.com/aws-amplify/amplify-adminui/issues/169'\n",
      "  'https://github.com/aws-amplify/docs/issues/1936'\n",
      "  'https://github.com/aws-amplify/amplify-js/issues/3621'\n",
      "  'https://github.com/aws-amplify/amplify-console/issues/1369'\n",
      "  'https://github.com/aws-amplify/amplify-js/issues/5354'\n",
      "  'https://github.com/aws-amplify/amplify-js/issues/7154'\n",
      "  'https://github.com/aws-amplify/amplify-console/issues/84'\n",
      "  'https://github.com/aws-amplify/amplify-js/issues/4776']]\n",
      "[[1.         0.5703742  0.53427687 0.32200108 0.31433721 0.31284222\n",
      "  0.29470813 0.27291282 0.23395244 0.23275672]]\n",
      "29.898285627365112\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "string = \"\"\"\n",
    "Attempting to view content, it appears the UI never finishes loading, the select table dropdown is in a disabled state, and the main window says \"fetching items...\".\n",
    "\n",
    "The browser console reports the following issue:\n",
    "\n",
    "Error: parsing failed: Syntax Error: Unexpected <EOF>.\n",
    "\n",
    "GraphQL request:1:1\n",
    "1 |\n",
    "  | ^\n",
    "    at app (main.ee81f266.chunk.js:1)\n",
    "    at 455.6c1c5071.chunk.js:2\n",
    "    at g (455.6c1c5071.chunk.js:2)\n",
    "    at 455.6c1c5071.chunk.js:2\n",
    "    at dispatch (455.6c1c5071.chunk.js:2)\n",
    "    at 455.6c1c5071.chunk.js:2\n",
    "    at 455.6c1c5071.chunk.js:2\n",
    "    at p (455.6c1c5071.chunk.js:2)\n",
    "    at v (455.6c1c5071.chunk.js:2)\n",
    "    at h (455.6c1c5071.chunk.js:2)\n",
    "additionally, there are network response issues:\n",
    "\n",
    "from app/env/details - error: \"Cannot read property 'defaultAuthentication' of undefined\"\n",
    "from app/env/getModels - error: \"ResourceNotFoundException: API models not found.\"\n",
    "\"\"\"\n",
    "sentence = [string]\n",
    "print(pipe.predict(sentence))\n",
    "print(pipe.score(sentence))\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84838\n"
     ]
    }
   ],
   "source": [
    "print(len(pipe['vectorsimilarity']._Vectors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amplify-android', 'amplify-codegen', 'amplify-js-samples', 'amplify-ios', 'amplify-adminui', 'amplify-js', 'aws-sdk-android', 'docs', 'amplify-console', 'amplify-flutter', 'amplify-ci-support', 'amplify-cli', 'aws-sdk-ios']\n"
     ]
    }
   ],
   "source": [
    "repo_list = list(set(df['repository']))\n",
    "print(repo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['repository'])\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "query = (df['repository'] == 'amplify-js') & (df['number'] == 8485)\n",
    "js_issue = str(df[query]['body'])\n",
    "# print(js_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AWS Support asked me to raise this here as they can't find a solution and will escalate to you.I am building a Typescript/Next.js/React/Redux app and I am trying to pass the user object via the props from the _app.tsx pageI get a ```The user is not authenticated``` error when calling ```currentAuthenticatedUser()```. I am not using federated login.The user object is returned with the logged in user.It happens as soon as you navigate to the base URL of the app.\"\n",
      "AWS Support asked me to raise this here as they can't find a solution and will escalate to you.I am building a Typescript/Next.js/React/Redux app and I am trying to pass the user object via the props from the _app.tsx pageI get a ```The user is not authenticated``` error when calling ```currentAuthenticatedUser()```. I am not using federated login.The user object is returned with the logged in user.It happens as soon as you navigate to the base URL of the app.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "begin_text = r'.*Describe the bug'\n",
    "mid_text = r'### Expected behavior|### Reproduction steps|\\r\\n*'\n",
    "end_text = r'### Code Snippet.*'\n",
    "pat_cases = '({}|{}|{})'.format(begin_text, mid_text, end_text)\n",
    "pat = re.compile(pat_cases, flags=(re.DOTALL | re.M))\n",
    "# print(type(pat))\n",
    "cleaned_issue = re.sub(pat, '', js_issue)\n",
    "# cleaned_issue = re.sub('\\r\\n*', '', cleaned_issue)\n",
    "# cleaned_issue = cleaned_issue.rstrip()\n",
    "print(repr(cleaned_issue))\n",
    "print(cleaned_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "string = 'hellohellotesthellohello'\n",
    "string = re.sub('hello*', '', string)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'hello', 'test', 'donuts']\n",
      "['', 'hello', 'test', 'donuts']\n"
     ]
    }
   ],
   "source": [
    "string = '\\r\\nhello\\r\\ntest\\r\\ndonuts'\n",
    "string = string.splitlines()\n",
    "print(repr(string))\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'33    Assume I have the following model:\\r\\n\\r\\n```graphql\\r\\ntype Employee\\r\\n@model \\r\\n@key(name: \"byInstitute\", fields: [\"instituteId\"], queryField: \"listEmployeesByInstitute\")\\r\\n{\\r\\n  id: ID!\\r\\n  instituteId: ID @assert(condition: \".length() > 1\") \\r\\n  institute: Institute @connection(keyField: \"instituteId\")\\r\\n  userId: ID @assert(condition: \".length() > 1\") \\r\\n  user: User @connection(keyField: \"userId\")\\r\\n}\\r\\n```\\r\\n\\r\\nThe question is if I want to have list of employees of an institute sorted by their names, how can I create the sort key?\\r\\n\\r\\nI mean something like this:\\r\\n\\r\\n```graphql\\r\\n@key(name: \"byInstitute\", fields: [\"instituteId\", \"user.name\"], queryField: \"listEmployeesByInstitute\")\\r\\n```\\r\\nIs it possible?\\nName: body, dtype: string'\n"
     ]
    }
   ],
   "source": [
    "query = (df['repository'] == 'amplify-cli') & (df['number'] == 6609)\n",
    "cli_issue = str(df[query]['body'])\n",
    "\n",
    "print(repr(cli_issue))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
